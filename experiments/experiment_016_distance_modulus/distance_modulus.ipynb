{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "848e4ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "from scipy.odr import ODR, Model, RealData\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "ROOT_PATH = os.environ.get('ROOT_PATH')\n",
    "if not ROOT_PATH in sys.path: sys.path.append(ROOT_PATH)\n",
    "\n",
    "from src.utils.constants import *\n",
    "from src.utils.CosmoFunc import *\n",
    "from src.filepaths import GENRMOCKFP_TEMPLATE_FILEPATH, GENRMOCKFP_CPP_FILEPATH\n",
    "from src.utils.functions import density_contour\n",
    "from src.A_generate_mocks import generate_genrmockfp_file\n",
    "\n",
    "\n",
    "def bin_data(x: np.array, y: np.array, xmin: float, xmax: float, n_bin: int):\n",
    "    # x_bin = np.linspace(np.min(x), np.max(x), n_bin)\n",
    "    x_bin = np.linspace(xmin, xmax, n_bin)\n",
    "    x_middle = 0.5 * (x_bin[1:] + x_bin[:-1])\n",
    "    delta_x = np.diff(x_bin)[0]\n",
    "\n",
    "    x_bin_ = []\n",
    "    y_bin = []\n",
    "    y_bin_err = []\n",
    "    y_bin_stderr = []\n",
    "\n",
    "    for x_trial in x_middle:\n",
    "        x_lower = x_trial - 0.5 * delta_x \n",
    "        x_upper = x_trial + 0.5 * delta_x\n",
    "\n",
    "        y_ = y[(x >= x_lower) & (x < x_upper)]\n",
    "\n",
    "        if len(y_):\n",
    "            x_bin_.append(x_trial)\n",
    "            y_bin.append(np.median(y_))\n",
    "            y_bin_err.append(np.std(y_))\n",
    "            y_bin_stderr.append(np.std(y_) / np.sqrt(len(y_)))\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return np.array(x_bin_), np.array(y_bin), np.array(y_bin_err), np.array(y_bin_stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac0f67b",
   "metadata": {},
   "source": [
    "# Calculate distance modulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45460d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = \"LAMOST\"\n",
    "\n",
    "df = pd.read_csv(f\"../../data/foundation/logdist/smin_setting_1/fp_fit_method_0/{survey.lower()}.csv\")\n",
    "\n",
    "# Logdist from individual fit\n",
    "df[\"logdist_individual_fp\"] = df[f\"logdist_{survey.lower()}\"]\n",
    "df[\"logdist_err_individual_fp\"] = df[f\"logdist_err_{survey.lower()}\"]\n",
    "\n",
    "# Logdist from combined fit\n",
    "df[\"logdist_combined_fp\"] = df[\"logdist_all_combined\"]\n",
    "df[\"logdist_err_combined_fp\"] = df[\"logdist_err_all_combined\"]\n",
    "\n",
    "# Calculate luminosity distance (in Mpc)\n",
    "red_spline, lumred_spline, dist_spline, lumdist_spline, ez_spline = rz_table()\n",
    "d_C = sp.interpolate.splev(df[\"z_dist_est\"].to_numpy(), dist_spline)\n",
    "d_L = (1 + df[\"zhelio\"]) * d_C\n",
    "\n",
    "# Calculate distance modulus\n",
    "df[\"DM_individual_fp\"] = 5 * np.log10(d_L) - 5 * df[\"logdist_individual_fp\"] + 25\n",
    "df[\"eDM_individual_fp\"] = 5 * np.log10(d_L) - 5 * df[\"logdist_err_individual_fp\"] + 25\n",
    "\n",
    "df[\"DM_combined_fp\"] = 5 * np.log10(d_L) - 5 * df[\"logdist_combined_fp\"] + 25\n",
    "df[\"eDM_combined_fp\"] = 5 * df[\"logdist_err_combined_fp\"]\n",
    "\n",
    "df.to_csv(f\"./dist_mod/{survey.lower()}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df8ef1d",
   "metadata": {},
   "source": [
    "# Calculate group-average distance moduli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15dc486a",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = \"SDSS\"\n",
    "\n",
    "df_full = pd.read_csv(f\"./dist_mod/{survey.lower()}.csv\")\n",
    "\n",
    "id_mapper = {\n",
    "    \"6dFGS\": \"_6dFGS\",\n",
    "    \"SDSS\": \"objid\",\n",
    "    \"LAMOST\": \"obsid\"\n",
    "}\n",
    "\n",
    "# Remove field galaxies\n",
    "df = df_full.copy()\n",
    "if survey == \"6dFGS\":\n",
    "    df = df[df[\"Group\"] != 0]\n",
    "else:\n",
    "    df = df[df[\"Group\"] != -1]\n",
    "\n",
    "# Calculate weight\n",
    "df[\"w_individual_fp\"] = 1 / df[\"eDM_individual_fp\"]**2\n",
    "df[\"w_combined_fp\"] = 1 / df[\"eDM_combined_fp\"]**2\n",
    "\n",
    "# Calculate weight * DM\n",
    "df[\"w_x_DM_individual_fp\"] = df[\"w_individual_fp\"] * df[\"DM_individual_fp\"]\n",
    "df[\"w_x_DM_combined_fp\"] = df[\"w_combined_fp\"] * df[\"DM_combined_fp\"]\n",
    "\n",
    "# Group by Group ID\n",
    "df_grouped = df.groupby(by=\"Group\", observed=False).agg(\n",
    "    numerator_individual_fp=(\"w_x_DM_individual_fp\", \"sum\"),\n",
    "    denominator_individual_fp=(\"w_individual_fp\", \"sum\"),\n",
    "    numerator_combined_fp=(\"w_x_DM_combined_fp\", \"sum\"),\n",
    "    denominator_combined_fp=(\"w_combined_fp\", \"sum\"),\n",
    ")\n",
    "\n",
    "df_grouped[\"group_DM_individual_fp\"] = df_grouped[\"numerator_individual_fp\"] / df_grouped[\"denominator_individual_fp\"]\n",
    "df_grouped[\"group_eDM_individual_fp\"] = 1 / np.sqrt(df_grouped[\"denominator_individual_fp\"])\n",
    "\n",
    "df_grouped[\"group_DM_combined_fp\"] = df_grouped[\"numerator_combined_fp\"] / df_grouped[\"denominator_combined_fp\"]\n",
    "df_grouped[\"group_eDM_combined_fp\"] = 1 / np.sqrt(df_grouped[\"denominator_combined_fp\"])\n",
    "\n",
    "df_grouped = df_grouped.reset_index()[[\"Group\", \"group_DM_individual_fp\", \"group_eDM_individual_fp\", \"group_DM_combined_fp\", \"group_eDM_combined_fp\"]]\n",
    "\n",
    "# Join back to original data\n",
    "df_final = df_full.merge(df_grouped, on=\"Group\", how=\"left\")\n",
    "\n",
    "# Use individual measurements for field galaxies\n",
    "df_final[\"group_DM_individual_fp\"] = df_final[\"group_DM_individual_fp\"].fillna(df_final[\"DM_individual_fp\"])\n",
    "df_final[\"group_eDM_individual_fp\"] = df_final[\"group_eDM_individual_fp\"].fillna(df_final[\"eDM_individual_fp\"])\n",
    "\n",
    "df_final[\"group_DM_combined_fp\"] = df_final[\"group_DM_combined_fp\"].fillna(df_final[\"DM_combined_fp\"])\n",
    "df_final[\"group_eDM_combined_fp\"] = df_final[\"group_eDM_combined_fp\"].fillna(df_final[\"eDM_combined_fp\"])\n",
    "\n",
    "df_final = df_final[[\n",
    "    'tmass', id_mapper[survey], 'ra', 'dec', 'zhelio', 'z_cmb', 'z_dist_est',\n",
    "    'j_m_ext', 'extinction_j', 'kcor_j', 'r', 'er', 's', 'es', 'i', 'ei',\n",
    "    'Group', 'Nr', 'DM_individual_fp', 'eDM_individual_fp',\n",
    "    'DM_combined_fp', 'eDM_combined_fp', 'group_DM_individual_fp',\n",
    "    'group_eDM_individual_fp', 'group_DM_combined_fp', 'group_eDM_combined_fp'\n",
    "]]\n",
    "\n",
    "df_final.to_csv(f\"./group_avg/{survey.lower()}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edbbe3c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
