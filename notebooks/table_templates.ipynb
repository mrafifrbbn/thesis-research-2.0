{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to generate final tables in the paper using Jinja templating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from jinja2 import Template\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "root_dir = os.environ.get(\"ROOT_PATH\")\n",
    "if not root_dir in sys.path: sys.path.append(root_dir)\n",
    "\n",
    "from main_code.utils.functions import remove_outliers\n",
    "from main_code.utils.constants import *\n",
    "from main_code.utils.CosmoFunc import *\n",
    "from main_code.utils.logging_config import get_logger\n",
    "from main_code.utils.filepaths import *\n",
    "\n",
    "# Get environment variables from .env file\n",
    "ROOT_PATH = os.environ.get('ROOT_PATH')\n",
    "SMIN_SETTING = int(os.environ.get('SMIN_SETTING'))\n",
    "COMPLETENESS_SETTING = int(os.environ.get('COMPLETENESS_SETTING'))\n",
    "FP_FIT_METHOD = int(os.environ.get('FP_FIT_METHOD'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 1: individual FP fits and mock fits\n",
    "\n",
    "To use: change `fp_fit_method` to 0 or 1. Run separately for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table*}\n",
      "\\caption{The FP parameter fits from the data and mocks for the LAMOST and combined (6dFGS+SDSS+LAMOST) samples, obtained using either the full $f_n$ method or the partial $f_n$ method.}\n",
      "\\label{tab:data_vs_mock}\n",
      "\\resizebox{\\textwidth}{!}{\\begin{tabular}{crrrrrrrr}\n",
      "%\\toprule\n",
      "% \\cmidrule(r){2-5}\\cmidrule(r){6-9}\n",
      "\\multicolumn{1}{c}{} & \\multicolumn{2}{c}{6dFGS} & \\multicolumn{2}{c}{SDSS} & \\multicolumn{2}{c}{LAMOST} & \\multicolumn{2}{c}{6dFGS+SDSS+LAMOST} \\\\ \n",
      "\\cmidrule(r){2-3}\\cmidrule(r){4-5}\\cmidrule(r){6-7}\\cmidrule(r){8-9}\n",
      "\\multicolumn{1}{c}{Fit} & \\multicolumn{1}{c}{Data} & \\multicolumn{1}{c}{Mock} & \\multicolumn{1}{c}{Data} & \\multicolumn{1}{c}{Mock} & \\multicolumn{1}{c}{Data} & \\multicolumn{1}{c}{Mock} & \\multicolumn{1}{c}{Data} & \\multicolumn{1}{c}{Mock} \\\\ \n",
      "\\midrule\n",
      "$a$ & $1.438 \\pm 0.016$ & $1.439 \\pm 0.028$ & $1.437 \\pm 0.012$ & $1.436 \\pm 0.028$ & $1.599 \\pm 0.027$ & $1.481 \\pm 0.051$ & $1.506 \\pm 0.009$ & $1.507 \\pm 0.022$ \\\\\n",
      "$b$ & $-0.882 \\pm 0.006$ & $-0.882 \\pm 0.011$ & $-0.928 \\pm 0.006$ & $-0.927 \\pm 0.012$ & $-0.960 \\pm 0.010$ & $-0.910 \\pm 0.021$ & $-0.929 \\pm 0.004$ & $-0.929 \\pm 0.009$ \\\\\n",
      "$c$ & $-0.225 \\pm 0.040$ & $-0.229 \\pm 0.053$ & $-0.105 \\pm 0.032$ & $-0.105 \\pm 0.052$ & $-0.359 \\pm 0.062$ & $-0.257 \\pm 0.109$ & $-0.248 \\pm 0.023$ & $-0.249 \\pm 0.039$ \\\\\n",
      "$\\bar{r}$ & $0.155 \\pm 0.003$ & $0.155 \\pm 0.006$ & $0.122 \\pm 0.003$ & $0.123 \\pm 0.007$ & $-0.008 \\pm 0.004$ & $0.020 \\pm 0.008$ & $0.107 \\pm 0.002$ & $0.108 \\pm 0.004$ \\\\\n",
      "$\\bar{s}$ & $2.233 \\pm 0.002$ & $2.233 \\pm 0.004$ & $2.221 \\pm 0.002$ & $2.221 \\pm 0.005$ & $2.181 \\pm 0.004$ & $2.194 \\pm 0.007$ & $2.221 \\pm 0.001$ & $2.221 \\pm 0.003$ \\\\\n",
      "$\\bar{\\imath}$ & $3.210 \\pm 0.003$ & $3.210 \\pm 0.004$ & $3.194 \\pm 0.003$ & $3.194 \\pm 0.005$ & $3.270 \\pm 0.004$ & $3.268 \\pm 0.008$ & $3.219 \\pm 0.002$ & $3.219 \\pm 0.004$ \\\\\n",
      "$\\sigma_1$ & $0.043 \\pm 0.001$ & $0.043 \\pm 0.001$ & $0.045 \\pm 0.000$ & $0.045 \\pm 0.001$ & $0.055 \\pm 0.001$ & $0.054 \\pm 0.002$ & $0.047 \\pm 0.000$ & $0.047 \\pm 0.001$ \\\\\n",
      "$\\sigma_2$ & $0.294 \\pm 0.002$ & $0.294 \\pm 0.005$ & $0.284 \\pm 0.002$ & $0.284 \\pm 0.006$ & $0.286 \\pm 0.003$ & $0.275 \\pm 0.007$ & $0.296 \\pm 0.001$ & $0.296 \\pm 0.004$ \\\\\n",
      "$\\sigma_3$ & $0.171 \\pm 0.002$ & $0.171 \\pm 0.004$ & $0.172 \\pm 0.002$ & $0.172 \\pm 0.004$ & $0.178 \\pm 0.003$ & $0.166 \\pm 0.005$ & $0.174 \\pm 0.001$ & $0.174 \\pm 0.003$ \\\\ \n",
      "\\bottomrule\n",
      "\\end{tabular}}\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "fp_fit_method = 0\n",
    "\n",
    "raw_template = r\"\"\"\n",
    "\\begin{table*}\n",
    "\\caption{The FP parameter fits from the data and mocks for the LAMOST and combined (6dFGS+SDSS+LAMOST) samples, obtained using either the full $f_n$ method or the partial $f_n$ method.}\n",
    "\\label{tab:data_vs_mock}\n",
    "\\resizebox{\\textwidth}{!}{\\begin{tabular}{crrrrrrrr}\n",
    "%\\toprule\n",
    "% \\cmidrule(r){2-5}\\cmidrule(r){6-9}\n",
    "\\multicolumn{1}{c}{} & \\multicolumn{2}{c}{6dFGS} & \\multicolumn{2}{c}{SDSS} & \\multicolumn{2}{c}{LAMOST} & \\multicolumn{2}{c}{6dFGS+SDSS+LAMOST} \\\\ \n",
    "\\cmidrule(r){2-3}\\cmidrule(r){4-5}\\cmidrule(r){6-7}\\cmidrule(r){8-9}\n",
    "\\multicolumn{1}{c}{Fit} & \\multicolumn{1}{c}{Data} & \\multicolumn{1}{c}{Mock} & \\multicolumn{1}{c}{Data} & \\multicolumn{1}{c}{Mock} & \\multicolumn{1}{c}{Data} & \\multicolumn{1}{c}{Mock} & \\multicolumn{1}{c}{Data} & \\multicolumn{1}{c}{Mock} \\\\ \n",
    "\\midrule\n",
    "$a$ & {{data_a_6dfgs}} & {{mock_a_6dfgs}} & {{data_a_sdss}} & {{mock_a_sdss}} & {{data_a_lamost}} & {{mock_a_lamost}} & {{data_a_all_combined}} & {{mock_a_all_combined}} \\\\\n",
    "$b$ & {{data_b_6dfgs}} & {{mock_b_6dfgs}} & {{data_b_sdss}} & {{mock_b_sdss}} & {{data_b_lamost}} & {{mock_b_lamost}} & {{data_b_all_combined}} & {{mock_b_all_combined}} \\\\\n",
    "$c$ & {{data_c_6dfgs}} & {{mock_c_6dfgs}} & {{data_c_sdss}} & {{mock_c_sdss}} & {{data_c_lamost}} & {{mock_c_lamost}} & {{data_c_all_combined}} & {{mock_c_all_combined}} \\\\\n",
    "$\\bar{r}$ & {{data_rmean_6dfgs}} & {{mock_rmean_6dfgs}} & {{data_rmean_sdss}} & {{mock_rmean_sdss}} & {{data_rmean_lamost}} & {{mock_rmean_lamost}} & {{data_rmean_all_combined}} & {{mock_rmean_all_combined}} \\\\\n",
    "$\\bar{s}$ & {{data_smean_6dfgs}} & {{mock_smean_6dfgs}} & {{data_smean_sdss}} & {{mock_smean_sdss}} & {{data_smean_lamost}} & {{mock_smean_lamost}} & {{data_smean_all_combined}} & {{mock_smean_all_combined}} \\\\\n",
    "$\\bar{\\imath}$ & {{data_imean_6dfgs}} & {{mock_imean_6dfgs}} & {{data_imean_sdss}} & {{mock_imean_sdss}} & {{data_imean_lamost}} & {{mock_imean_lamost}} & {{data_imean_all_combined}} & {{mock_imean_all_combined}} \\\\\n",
    "$\\sigma_1$ & {{data_sigma1_6dfgs}} & {{mock_sigma1_6dfgs}} & {{data_sigma1_sdss}} & {{mock_sigma1_sdss}} & {{data_sigma1_lamost}} & {{mock_sigma1_lamost}} & {{data_sigma1_all_combined}} & {{mock_sigma1_all_combined}} \\\\\n",
    "$\\sigma_2$ & {{data_sigma2_6dfgs}} & {{mock_sigma2_6dfgs}} & {{data_sigma2_sdss}} & {{mock_sigma2_sdss}} & {{data_sigma2_lamost}} & {{mock_sigma2_lamost}} & {{data_sigma2_all_combined}} & {{mock_sigma2_all_combined}} \\\\\n",
    "$\\sigma_3$ & {{data_sigma3_6dfgs}} & {{mock_sigma3_6dfgs}} & {{data_sigma3_sdss}} & {{mock_sigma3_sdss}} & {{data_sigma3_lamost}} & {{mock_sigma3_lamost}} & {{data_sigma3_all_combined}} & {{mock_sigma3_all_combined}} \\\\ \n",
    "\\bottomrule\n",
    "\\end{tabular}}\n",
    "\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "FP_COLUMNS = [\"a\", \"b\", \"rmean\", \"smean\", \"imean\", \"sigma1\", \"sigma2\", \"sigma3\"]\n",
    "method_ = \"full_fn\" if fp_fit_method == 0 else \"partial_fn\"\n",
    "\n",
    "jinja_context = {}\n",
    "for survey in (SURVEY_LIST + [\"ALL_COMBINED\"]):\n",
    "\n",
    "    # Load data (MCMC chain) fits\n",
    "    type_ = \"data\"\n",
    "    survey_lowercase = survey.lower()\n",
    "    data = np.load(f\"../../artifacts/fp_fit/smin_setting_1/fp_fit_method_{fp_fit_method}/{survey_lowercase}_chain.npy\")\n",
    "    df_data = pd.DataFrame(data, columns=FP_COLUMNS)\n",
    "    df_data[\"c\"] = df_data[\"rmean\"] - df_data[\"a\"] * df_data[\"smean\"] - df_data[\"b\"] * df_data[\"imean\"]\n",
    "\n",
    "    for col in FP_COLUMNS + [\"c\"]:\n",
    "        x = df_data[col].to_numpy()\n",
    "\n",
    "        x, _ = remove_outliers(x)\n",
    "\n",
    "        mean = f\"{np.round(np.mean(x), 3):.3f}\"\n",
    "        std = f\"{np.round(np.std(x), 3):.3f}\"\n",
    "\n",
    "        jinja_context[f\"{type_}_{col}_{survey_lowercase}\"] = \"$\" + mean + \" \\pm \" + std + \"$\"\n",
    "\n",
    "\n",
    "    # Load mock fits\n",
    "    type_ = \"mock\"\n",
    "    df_mock = pd.read_csv(f\"../../artifacts/mock_fits/smin_setting_1/fp_fit_method_{fp_fit_method}/{survey_lowercase}_fit_with_{method_}.csv\")\n",
    "    df_mock[\"c\"] = df_mock[\"rmean\"] - df_mock[\"a\"] * df_mock[\"smean\"] - df_mock[\"b\"] * df_mock[\"imean\"]\n",
    "\n",
    "    for col in FP_COLUMNS + [\"c\"]:\n",
    "        x = df_mock[col].to_numpy()\n",
    "\n",
    "        x, _ = remove_outliers(x)\n",
    "\n",
    "        mean = f\"{np.round(np.mean(x), 3):.3f}\"\n",
    "        std = f\"{np.round(np.std(x), 3):.3f}\"\n",
    "\n",
    "        jinja_context[f\"{type_}_{col}_{survey_lowercase}\"] = \"$\" + mean + \" \\pm \" + std + \"$\"\n",
    "\n",
    "# Render the template using Jinja\n",
    "print(Template(raw_template).render(jinja_context))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 2: final FP ($abc$-fixed) summary and typical scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\\begin{table*}\n",
      "\\caption{The final set of FP parameters derived from the $abc$-fixed method. For all surveys, we use $a = 1.449 \\pm 0.012$, $b = -0.895 \\pm 0.005$, and $c = -0.227 \\pm 0.03$. $\\bar{r}$ is calculated as $\\bar{r} = c + a\\bar{s} + b\\bar{\\imath}$. We also give the error in $r$ due to the intrinsic scatter of the FP ($\\sigma_{r,\\mathrm{int}}$), the typical total error in $r$ in dex ($\\sigma_r$) and in percentage.}\n",
      "\\label{tab:final_fp_summary}\n",
      "\\resizebox{\\textwidth}{!}{\\begin{tabular}{crrrrrrrrr}\n",
      "\\multicolumn{1}{c}{Survey} & \\multicolumn{1}{c}{$\\bar{r}$} & \\multicolumn{1}{c}{$\\bar{s}$} & \\multicolumn{1}{c}{$\\bar{\\imath}$} & \\multicolumn{1}{c}{$\\sigma_1$} & \\multicolumn{1}{c}{$\\sigma_2$} & \\multicolumn{1}{c}{$\\sigma_3$} & \\multicolumn{1}{c}{$\\sigma_{r,\\mathrm{int}}$} & \\multicolumn{1}{c}{$\\sigma_r$} & \\multicolumn{1}{c}{$\\sigma_r$ (\\%)} \\\\\n",
      "\\midrule\n",
      "6dFGS & $0.183 \\pm 0.004$ & $2.267 \\pm 0.002$ & $3.213 \\pm 0.004$ & $0.044 \\pm 0.001$ & $0.288 \\pm 0.003$ & $0.144 \\pm 0.002$ & 0.086 & 0.115 & 26.5 \\\\\n",
      "SDSS & $0.16 \\pm 0.005$ & $2.235 \\pm 0.003$ & $3.186 \\pm 0.004$ & $0.045 \\pm 0.001$ & $0.273 \\pm 0.003$ & $0.164 \\pm 0.003$ & 0.089 & 0.094 & 21.7 \\\\\n",
      "LAMOST & $-0.036 \\pm 0.01$ & $2.158 \\pm 0.008$ & $3.281 \\pm 0.008$ & $0.049 \\pm 0.001$ & $0.276 \\pm 0.005$ & $0.168 \\pm 0.005$ & 0.096 & 0.114 & 26.2 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}}\n",
      "\\end{table*}\n"
     ]
    }
   ],
   "source": [
    "raw_template = r\"\"\"\n",
    "\\begin{table*}\n",
    "\\caption{The final set of FP parameters derived from the $abc$-fixed method. The best-fit slopes and zero-point are $a = 1.475 \\pm 0.014$, $b = -0.888 \\pm 0.005$, and $c = -0.308 \\pm 0.034$. We also give the error in $r$ due to the intrinsic scatter of the FP ($\\sigma_{r,\\mathrm{int}}$) and the rms total error in $r$ ($\\sigma_r$), both in dex and as a percentage.}\n",
    "\\label{tab:final_fp_summary}\n",
    "\\resizebox{\\textwidth}{!}{\\begin{tabular}{crrrrrrrrr}\n",
    "\\multicolumn{1}{c}{Survey} & \\multicolumn{1}{c}{$\\bar{r}$} & \\multicolumn{1}{c}{$\\bar{s}$} & \\multicolumn{1}{c}{$\\bar{\\imath}$} & \\multicolumn{1}{c}{$\\sigma_1$} & \\multicolumn{1}{c}{$\\sigma_2$} & \\multicolumn{1}{c}{$\\sigma_3$} & \\multicolumn{1}{c}{$\\sigma_{r,\\mathrm{int}}$} & \\multicolumn{1}{c}{$\\sigma_r$} & \\multicolumn{1}{c}{$\\sigma_r$ (\\%)} \\\\\n",
    "\\midrule\n",
    "6dFGS & {{data_rmean_6dfgs}} & {{data_smean_6dfgs}} & {{data_imean_6dfgs}} & {{data_sigma1_6dfgs}} & {{data_sigma2_6dfgs}} & {{data_sigma3_6dfgs}} & {{data_sigmar_int_6dfgs}} & {{data_sigmar_6dfgs}} & {{data_sigmar_pct_6dfgs}} \\\\\n",
    "SDSS & {{data_rmean_sdss}} & {{data_smean_sdss}} & {{data_imean_sdss}} & {{data_sigma1_sdss}} & {{data_sigma2_sdss}} & {{data_sigma3_sdss}} & {{data_sigmar_int_sdss}} & {{data_sigmar_sdss}} & {{data_sigmar_pct_sdss}} \\\\\n",
    "LAMOST & {{data_rmean_lamost}} & {{data_smean_lamost}} & {{data_imean_lamost}} & {{data_sigma1_lamost}} & {{data_sigma2_lamost}} & {{data_sigma3_lamost}} & {{data_sigmar_int_lamost}} & {{data_sigmar_lamost}} & {{data_sigmar_pct_lamost}} \\\\\n",
    "\\bottomrule\n",
    "\\end{tabular}}\n",
    "\\end{table*}\n",
    "\"\"\"\n",
    "\n",
    "# Initialize dictionary for templating\n",
    "jinja_context = {}\n",
    "\n",
    "# 1: FP parameters\n",
    "label_names = [\"rmean\", \"smean\", \"imean\", \"sigma1\", \"sigma2\", \"sigma3\"]\n",
    "for survey in SURVEY_LIST:\n",
    "    params = np.load(f\"../artifacts/fp_fit/smin_setting_1/fp_fit_method_0/{survey.lower()}_abc_fixed_chain.npy\").T\n",
    "\n",
    "    for i in range(params.shape[0]):\n",
    "        param = params[i]\n",
    "\n",
    "        mean_ = str(np.round(np.mean(param), 3))\n",
    "        std_ = str(np.round(np.std(param), 3))\n",
    "\n",
    "        # Text\n",
    "        text_ = \"$\" + mean_ + \" \\pm \" + std_ + \"$\"\n",
    "        jinja_context[f\"data_{label_names[i]}_{survey.lower()}\"] = text_\n",
    "\n",
    "# 2: FP scatter\n",
    "df = pd.read_csv(\"../artifacts/fp_fit/smin_setting_1/fp_fit_method_0/fp_scatter.csv\", index_col=0)\n",
    "for survey in SURVEY_LIST:\n",
    "    fp_scatter = df.loc[survey]\n",
    "\n",
    "    jinja_context[f\"data_sigmar_int_{survey.lower()}\"] = str(np.round(fp_scatter[\"sigma_r_int\"], 3))\n",
    "    jinja_context[f\"data_sigmar_{survey.lower()}\"] = str(np.round(fp_scatter[\"r_scatter\"], 3))\n",
    "    jinja_context[f\"data_sigmar_pct_{survey.lower()}\"] = str(np.round(fp_scatter[\"r_scatter_pct\"], 1))\n",
    "\n",
    "# 3: abc for caption\n",
    "params = np.load(\"../artifacts/fp_fit/smin_setting_1/fp_fit_method_0/all_combined_individual_chain.npy\").T\n",
    "labels = [\"a\", \"b\", \"c\"]\n",
    "for i, label in enumerate(labels):\n",
    "    param = params[i]\n",
    "\n",
    "    mean_ = str(np.round(np.mean(param), 3))\n",
    "    std_ = str(np.round(np.std(param), 3))\n",
    "\n",
    "    # Text\n",
    "    text_ =  mean_ + \" \\pm \" + std_\n",
    "    jinja_context[f\"data_{label}\"] = text_\n",
    "\n",
    "# Render the template using Jinja\n",
    "print(Template(raw_template).render(jinja_context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.44950138, -0.88863709, -0.25055551, ...,  0.04541382,\n",
       "         0.28585853,  0.15598145],\n",
       "       [ 1.44728843, -0.88837185, -0.24396168, ...,  0.04575763,\n",
       "         0.28385868,  0.15853   ],\n",
       "       [ 1.45359872, -0.89250893, -0.24415899, ...,  0.04548636,\n",
       "         0.28347499,  0.15719976],\n",
       "       ...,\n",
       "       [ 1.43898727, -0.89213686, -0.21295444, ...,  0.04416694,\n",
       "         0.28708783,  0.157268  ],\n",
       "       [ 1.4665193 , -0.8930568 , -0.27336978, ...,  0.04534259,\n",
       "         0.28833849,  0.15795641],\n",
       "       [ 1.45409118, -0.89333447, -0.24303942, ...,  0.04539166,\n",
       "         0.28312578,  0.15692559]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
